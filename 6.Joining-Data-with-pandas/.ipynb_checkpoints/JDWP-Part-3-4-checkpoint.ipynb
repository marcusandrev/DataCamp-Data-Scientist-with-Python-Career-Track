{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "830c21d1",
   "metadata": {},
   "source": [
    "# Joining Data with pandas Part 3 - 4\n",
    "\n",
    "## Course Description\n",
    "\n",
    "Being able to combine and work with multiple datasets is an essential skill for any aspiring Data Scientist. Pandas is a crucial cornerstone of the Python data science ecosystem, with Stack Overflow recording 5 million views for pandas questions. Learn to handle multiple DataFrames by combining, organizing, joining, and reshaping them using pandas. You'll work with datasets from the World Bank and the City Of Chicago. You will finish the course with a solid skillset for data-joining in pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd12950",
   "metadata": {},
   "source": [
    "## Advance Merging and Concantenating\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fd6bd5",
   "metadata": {},
   "source": [
    "## Steps of a semi-join\n",
    "In the last video, you were shown how to perform a semi-join with pandas. In this exercise, you'll solidify your understanding of the necessary steps. Recall that a semi-join filters the left table to only the rows where a match exists in both the left and right tables.\n",
    "\n",
    "<b><u> Answer:<u/></b> <br />\n",
    "    1. Merge the left and right tables on key column using an inner-join. <br />\n",
    "    2. Search if the key column in the left table is in the merged tables using the <code>.isin()</code> method creating a Boolean <code>Series</code>. <br />\n",
    "    3. Subset the rows of the left table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1398311",
   "metadata": {},
   "source": [
    "### Performing an anti-join\n",
    "In our music streaming company dataset, each customer is assigned an employee representative to assist them. In this exercise, filter the employee table by a table of top customers, returning only those employees who are not assigned to a customer. The results should resemble the results of an anti-join. The company's leadership will assign these employees additional training so that they can work with high valued customers.\n",
    "\n",
    "<b>Instructions:</b>\n",
    "- Merge employees and top_cust with a left join, setting indicator argument to True. Save the result to empl_cust.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed939733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can't find employees and top_cust datasets\n",
    "\n",
    "# Merge employees and top_cust\n",
    "empl_cust = employees.merge(top_cust, on='srid', \n",
    "                            how='left', indicator=True)\n",
    "\n",
    "# Select the srid column where _merge is left_only\n",
    "srid_list = empl_cust.loc[empl_cust['_merge'] == 'left_only', 'srid']\n",
    "\n",
    "# Get employees not working with top customers\n",
    "print(employees[employees['srid'].isin(srid_list)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb661aed",
   "metadata": {},
   "source": [
    "### Performing a semi-join\n",
    "Some of the tracks that have generated the most significant amount of revenue are from TV-shows or are other non-musical audio. You have been given a table of invoices that include top revenue-generating items. Additionally, you have a table of non-musical tracks from the streaming service. In this exercise, you'll use a semi-join to find the top revenue-generating non-musical tracks.\n",
    "\n",
    "<b>Instructions:</b>\n",
    "- Merge non_mus_tcks and top_invoices on tid using an inner join. Save the result as tracks_invoices.\n",
    "- Use .isin() to subset the rows of non_mus_tck where tid is in the tid column of tracks_invoices. Save the result as top_tracks.\n",
    "- Group top_tracks by gid and count the tid rows. Save the result to cnt_by_gid.\n",
    "- Merge cnt_by_gid with the genres table on gid and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934fa96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can't find the datasets\n",
    "\n",
    "# Merge the non_mus_tck and top_invoices tables on tid\n",
    "tracks_invoices = non_mus_tcks.merge(top_invoices, on=\"tid\")\n",
    "\n",
    "# Use .isin() to subset non_mus_tcks to rows with tid in tracks_invoices\n",
    "top_tracks = non_mus_tcks[non_mus_tcks['tid'].isin(tracks_invoices['tid'])]\n",
    "\n",
    "# Group the top_tracks by gid and count the tid rows\n",
    "cnt_by_gid = top_tracks.groupby(['gid'], as_index=False).agg({'tid':\"count\"})\n",
    "\n",
    "# Merge the genres table to cnt_by_gid on gid and print\n",
    "print(cnt_by_gid.merge(genres, on=\"gid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62f1308",
   "metadata": {},
   "source": [
    "### Concatenation basics\n",
    "You have been given a few tables of data with musical track info for different albums from the metal band, Metallica. The track info comes from their Ride The Lightning, Master Of Puppets, and St. Anger albums. Try various features of the .concat() method by concatenating the tables vertically together in different ways.\n",
    "\n",
    "<b>Instructions:</b>\n",
    "- Concatenate tracks_master, tracks_ride, and tracks_st, in that order, setting sort to True.\n",
    "- Concatenate tracks_master, tracks_ride, and tracks_st, where the index goes from 0 to n-1.\n",
    "- Concatenate tracks_master, tracks_ride, and tracks_st, showing only columns that are in all tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a593a4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No datasets\n",
    "\n",
    "# Concatenate tracks_master, tracks_ride, and tracks_st, in that order, setting sort to True.\n",
    "\n",
    "# Concatenate the tracks\n",
    "tracks_from_albums = pd.concat([tracks_master,tracks_ride,tracks_st],\n",
    "                               sort=True)\n",
    "print(tracks_from_albums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56056870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No datasets\n",
    "\n",
    "# Concatenate tracks_master, tracks_ride, and tracks_st, where the index goes from 0 to n-1.\n",
    "\n",
    "# Concatenate the tracks so the index goes from 0 to n-1\n",
    "tracks_from_albums = pd.concat([tracks_master,tracks_ride,tracks_st],\n",
    "                               ignore_index=True,\n",
    "                               sort=True)\n",
    "print(tracks_from_albums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06305ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No datasets\n",
    "\n",
    "# Concatenate tracks_master, tracks_ride, and tracks_st, showing only columns that are in all tables.\n",
    "\n",
    "\n",
    "# Concatenate the tracks, show only columns names that are in all tables\n",
    "tracks_from_albums = pd.concat([tracks_master,tracks_ride,tracks_st],\n",
    "                               join=\"inner\",\n",
    "                               sort=True)\n",
    "print(tracks_from_albums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c56502c",
   "metadata": {},
   "source": [
    "### Concatenating with keys\n",
    "The leadership of the music streaming company has come to you and asked you for assistance in analyzing sales for a recent business quarter. They would like to know which month in the quarter saw the highest average invoice total. You have been given three tables with invoice data named inv_jul, inv_aug, and inv_sep. Concatenate these tables into one to create a graph of the average monthly invoice total.\n",
    "\n",
    "<b>Instructions:</b>\n",
    "- Concatenate the three tables together vertically in order with the oldest month first, adding '7Jul', '8Aug', and '9Sep' as keys for their respective months, and save to variable avg_inv_by_month.\n",
    "- Use the .agg() method to find the average of the total column from the grouped invoices.\n",
    "- Create a bar chart of avg_inv_by_month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d987aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No datasets\n",
    "\n",
    "# Concatenate the tables and add keys\n",
    "inv_jul_thr_sep = pd.concat([inv_jul,inv_aug,inv_sep], \n",
    "                            keys=[\"7Jul\", \"8Aug\", \"9Sep\"])\n",
    "\n",
    "# Group the invoices by the index keys and find avg of the total column\n",
    "avg_inv_by_month = inv_jul_thr_sep.groupby(level=0).agg({'total':'mean'})\n",
    "\n",
    "# Bar plot of avg_inv_by_month\n",
    "avg_inv_by_month.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26a03f4",
   "metadata": {},
   "source": [
    "### Using the append method\n",
    "The .concat() method is excellent when you need a lot of control over how concatenation is performed. However, if you do not need as much control, then the .append() method is another option. You'll try this method out by appending the track lists together from different Metallica albums. From there, you will merge it with the invoice_items table to determine which track sold the most.\n",
    "\n",
    "<b>Instructions:</b>\n",
    "- Use the .append() method to combine (in this order)tracks_ride, tracks_master, and tracks_st together vertically, and save to metallica_tracks.\n",
    "- Merge metallica_tracks and invoice_items on tid with an inner join, and save to tracks_invoices.\n",
    "- For each tid and name in tracks_invoices, sum the quantity sold column, and save as tracks_sold.\n",
    "- Sort tracks_sold in descending order by the quantity column, and print the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9862d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No datasets\n",
    "\n",
    "# Use the .append() method to combine the tracks tables\n",
    "metallica_tracks = tracks_ride.append([tracks_master, tracks_st], sort=False)\n",
    "\n",
    "# Merge metallica_tracks and invoice_items\n",
    "tracks_invoices = metallica_tracks.merge(invoice_items, on=\"tid\")\n",
    "\n",
    "# For each tid and name sum the quantity sold\n",
    "tracks_sold = tracks_invoices.groupby(['tid','name']).agg({\"quantity\":\"sum\"})\n",
    "\n",
    "# Sort in decending order by quantity and print the results\n",
    "print(tracks_sold.sort_values(['quantity'],ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a4fd4b",
   "metadata": {},
   "source": [
    "### Concatenate and merge to find common songs\n",
    "The senior leadership of the streaming service is requesting your help again. You are given the historical files for a popular playlist in the classical music genre in 2018 and 2019. Additionally, you are given a similar set of files for the most popular pop music genre playlist on the streaming service in 2018 and 2019. Your goal is to concatenate the respective files to make a large classical playlist table and overall popular music table. Then filter the classical music table using a semi-join to return only the most popular classical music tracks.\n",
    "\n",
    "<b>Instructions:</b>\n",
    "- Concatenate the classic_18 and classic_19 tables vertically where the index goes from 0 to n-1, and save to classic_18_19.\n",
    "- Concatenate the pop_18 and pop_19 tables vertically where the index goes from 0 to n-1, and save to pop_18_19.\n",
    "- With classic_18_19 on the left, merge it with pop_18_19 on tid using an inner join.\n",
    "- Use .isin() to filter classic_18_19 where tid is in classic_pop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ed10f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No datasets\n",
    "\n",
    "# Concatenate the classic tables vertically\n",
    "classic_18_19 = pd.concat([classic_18, classic_19], ignore_index=True)\n",
    "\n",
    "# Concatenate the pop tables vertically\n",
    "pop_18_19 = pd.concat([pop_18, pop_19], ignore_index=True)\n",
    "\n",
    "# Merge classic_18_19 with pop_18_19\n",
    "classic_pop = classic_18_19.merge(pop_18_19, on=\"tid\", how=\"inner\")\n",
    "\n",
    "# Using .isin(), filter classic_18_19 rows where tid is in classic_pop\n",
    "popular_classic = classic_18_19[classic_18_19[\"tid\"].isin(classic_pop['tid'])]\n",
    "\n",
    "# Print popular chart\n",
    "print(popular_classic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d078c2c",
   "metadata": {},
   "source": [
    "## Merging Ordered and Time-Series Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d91d317",
   "metadata": {},
   "source": [
    "## Correlation between GDP and S&P500\n",
    "In this exercise, you want to analyze stock returns from the S&P 500. You believe there may be a relationship between the returns of the S&P 500 and the GDP of the US. Merge the different datasets together to compute the correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f065d993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>-38.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>23.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>12.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>13.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Date  Returns\n",
       "0  2008   -38.49\n",
       "1  2009    23.45\n",
       "2  2010    12.78\n",
       "3  2011     0.00\n",
       "4  2012    13.41"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sp500 = pd.read_csv(\"datasets/S&P500.csv\")\n",
    "sp500.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f73fdff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Indicator Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>GDP (current US$)</td>\n",
       "      <td>2010</td>\n",
       "      <td>6.087160e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Germany</td>\n",
       "      <td>DEU</td>\n",
       "      <td>GDP (current US$)</td>\n",
       "      <td>2010</td>\n",
       "      <td>3.417090e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Japan</td>\n",
       "      <td>JPN</td>\n",
       "      <td>GDP (current US$)</td>\n",
       "      <td>2010</td>\n",
       "      <td>5.700100e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United States</td>\n",
       "      <td>USA</td>\n",
       "      <td>GDP (current US$)</td>\n",
       "      <td>2010</td>\n",
       "      <td>1.499210e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>GDP (current US$)</td>\n",
       "      <td>2011</td>\n",
       "      <td>7.551500e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Country Name Country Code     Indicator Name  Year           GDP\n",
       "0          China          CHN  GDP (current US$)  2010  6.087160e+12\n",
       "1        Germany          DEU  GDP (current US$)  2010  3.417090e+12\n",
       "2          Japan          JPN  GDP (current US$)  2010  5.700100e+12\n",
       "3  United States          USA  GDP (current US$)  2010  1.499210e+13\n",
       "4          China          CHN  GDP (current US$)  2011  7.551500e+12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdp = pd.read_csv(\"datasets/WorldBank_GDP.csv\")\n",
    "gdp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782ba32c",
   "metadata": {},
   "source": [
    "<b>Instructions:</b>\n",
    "- Use merge_ordered() to merge gdp and sp500 using a left join on year and date. Save the results as gdp_sp500.\n",
    "- Print gdp_sp500 and look at the returns for the year 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29344939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Country Name Country Code     Indicator Name  Year           GDP    Date  \\\n",
      "0           China          CHN  GDP (current US$)  2010  6.087160e+12  2010.0   \n",
      "1         Germany          DEU  GDP (current US$)  2010  3.417090e+12  2010.0   \n",
      "2           Japan          JPN  GDP (current US$)  2010  5.700100e+12  2010.0   \n",
      "3   United States          USA  GDP (current US$)  2010  1.499210e+13  2010.0   \n",
      "4           China          CHN  GDP (current US$)  2011  7.551500e+12  2011.0   \n",
      "5         Germany          DEU  GDP (current US$)  2011  3.757700e+12  2011.0   \n",
      "6           Japan          JPN  GDP (current US$)  2011  6.157460e+12  2011.0   \n",
      "7   United States          USA  GDP (current US$)  2011  1.554260e+13  2011.0   \n",
      "8           China          CHN  GDP (current US$)  2012  8.532230e+12  2012.0   \n",
      "9         Germany          DEU  GDP (current US$)  2012  3.543980e+12  2012.0   \n",
      "10          Japan          JPN  GDP (current US$)  2012  6.203210e+12  2012.0   \n",
      "11  United States          USA  GDP (current US$)  2012  1.619700e+13  2012.0   \n",
      "12          China          CHN  GDP (current US$)  2012  8.532230e+12  2012.0   \n",
      "13        Germany          DEU  GDP (current US$)  2012  3.543980e+12  2012.0   \n",
      "14          Japan          JPN  GDP (current US$)  2012  6.203210e+12  2012.0   \n",
      "15  United States          USA  GDP (current US$)  2012  1.619700e+13  2012.0   \n",
      "16          China          CHN  GDP (current US$)  2013  9.570410e+12  2013.0   \n",
      "17        Germany          DEU  GDP (current US$)  2013  3.752510e+12  2013.0   \n",
      "18          Japan          JPN  GDP (current US$)  2013  5.155720e+12  2013.0   \n",
      "19  United States          USA  GDP (current US$)  2013  1.678480e+13  2013.0   \n",
      "20          China          CHN  GDP (current US$)  2014  1.043850e+13  2014.0   \n",
      "21        Germany          DEU  GDP (current US$)  2014  3.898730e+12  2014.0   \n",
      "22          Japan          JPN  GDP (current US$)  2014  4.850410e+12  2014.0   \n",
      "23  United States          USA  GDP (current US$)  2014  1.752170e+13  2014.0   \n",
      "24          China          CHN  GDP (current US$)  2015  1.101550e+13  2015.0   \n",
      "25        Germany          DEU  GDP (current US$)  2015  3.381390e+12  2015.0   \n",
      "26          Japan          JPN  GDP (current US$)  2015  4.389480e+12  2015.0   \n",
      "27  United States          USA  GDP (current US$)  2015  1.821930e+13  2015.0   \n",
      "28          China          CHN  GDP (current US$)  2016  1.113790e+13  2016.0   \n",
      "29        Germany          DEU  GDP (current US$)  2016  3.495160e+12  2016.0   \n",
      "30          Japan          JPN  GDP (current US$)  2016  4.926670e+12  2016.0   \n",
      "31  United States          USA  GDP (current US$)  2016  1.870720e+13  2016.0   \n",
      "32          China          CHN  GDP (current US$)  2017  1.214350e+13  2017.0   \n",
      "33        Germany          DEU  GDP (current US$)  2017  3.693200e+12  2017.0   \n",
      "34          Japan          JPN  GDP (current US$)  2017  4.859950e+12  2017.0   \n",
      "35  United States          USA  GDP (current US$)  2017  1.948540e+13  2017.0   \n",
      "36          China          CHN  GDP (current US$)  2018  1.360820e+13     NaN   \n",
      "37        Germany          DEU  GDP (current US$)  2018  3.996760e+12     NaN   \n",
      "38          Japan          JPN  GDP (current US$)  2018  4.970920e+12     NaN   \n",
      "39  United States          USA  GDP (current US$)  2018  2.049410e+13     NaN   \n",
      "\n",
      "    Returns  \n",
      "0     12.78  \n",
      "1     12.78  \n",
      "2     12.78  \n",
      "3     12.78  \n",
      "4      0.00  \n",
      "5      0.00  \n",
      "6      0.00  \n",
      "7      0.00  \n",
      "8     13.41  \n",
      "9     13.41  \n",
      "10    13.41  \n",
      "11    13.41  \n",
      "12    13.41  \n",
      "13    13.41  \n",
      "14    13.41  \n",
      "15    13.41  \n",
      "16    29.60  \n",
      "17    29.60  \n",
      "18    29.60  \n",
      "19    29.60  \n",
      "20    11.39  \n",
      "21    11.39  \n",
      "22    11.39  \n",
      "23    11.39  \n",
      "24    -0.73  \n",
      "25    -0.73  \n",
      "26    -0.73  \n",
      "27    -0.73  \n",
      "28     9.54  \n",
      "29     9.54  \n",
      "30     9.54  \n",
      "31     9.54  \n",
      "32    19.42  \n",
      "33    19.42  \n",
      "34    19.42  \n",
      "35    19.42  \n",
      "36      NaN  \n",
      "37      NaN  \n",
      "38      NaN  \n",
      "39      NaN  \n"
     ]
    }
   ],
   "source": [
    "# Use merge_ordered() to merge gdp and sp500 on year and date\n",
    "gdp_sp500 = pd.merge_ordered(gdp, sp500, left_on=\"Year\", right_on=\"Date\", \n",
    "                             how=\"left\")\n",
    "\n",
    "# Print gdp_sp500\n",
    "print(gdp_sp500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a5dc0f",
   "metadata": {},
   "source": [
    "<b>Instructions:</b>\n",
    "- Use merge_ordered(), again similar to before, to merge gdp and sp500 use the function's ability to interpolate missing data to forward fill the missing value for returns, assigning this table to the variable gdp_sp500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb5da501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Country Name Country Code     Indicator Name  Year           GDP  Date  \\\n",
      "0           China          CHN  GDP (current US$)  2010  6.087160e+12  2010   \n",
      "1         Germany          DEU  GDP (current US$)  2010  3.417090e+12  2010   \n",
      "2           Japan          JPN  GDP (current US$)  2010  5.700100e+12  2010   \n",
      "3   United States          USA  GDP (current US$)  2010  1.499210e+13  2010   \n",
      "4           China          CHN  GDP (current US$)  2011  7.551500e+12  2011   \n",
      "5         Germany          DEU  GDP (current US$)  2011  3.757700e+12  2011   \n",
      "6           Japan          JPN  GDP (current US$)  2011  6.157460e+12  2011   \n",
      "7   United States          USA  GDP (current US$)  2011  1.554260e+13  2011   \n",
      "8           China          CHN  GDP (current US$)  2012  8.532230e+12  2012   \n",
      "9         Germany          DEU  GDP (current US$)  2012  3.543980e+12  2012   \n",
      "10          Japan          JPN  GDP (current US$)  2012  6.203210e+12  2012   \n",
      "11  United States          USA  GDP (current US$)  2012  1.619700e+13  2012   \n",
      "12          China          CHN  GDP (current US$)  2012  8.532230e+12  2012   \n",
      "13        Germany          DEU  GDP (current US$)  2012  3.543980e+12  2012   \n",
      "14          Japan          JPN  GDP (current US$)  2012  6.203210e+12  2012   \n",
      "15  United States          USA  GDP (current US$)  2012  1.619700e+13  2012   \n",
      "16          China          CHN  GDP (current US$)  2013  9.570410e+12  2013   \n",
      "17        Germany          DEU  GDP (current US$)  2013  3.752510e+12  2013   \n",
      "18          Japan          JPN  GDP (current US$)  2013  5.155720e+12  2013   \n",
      "19  United States          USA  GDP (current US$)  2013  1.678480e+13  2013   \n",
      "20          China          CHN  GDP (current US$)  2014  1.043850e+13  2014   \n",
      "21        Germany          DEU  GDP (current US$)  2014  3.898730e+12  2014   \n",
      "22          Japan          JPN  GDP (current US$)  2014  4.850410e+12  2014   \n",
      "23  United States          USA  GDP (current US$)  2014  1.752170e+13  2014   \n",
      "24          China          CHN  GDP (current US$)  2015  1.101550e+13  2015   \n",
      "25        Germany          DEU  GDP (current US$)  2015  3.381390e+12  2015   \n",
      "26          Japan          JPN  GDP (current US$)  2015  4.389480e+12  2015   \n",
      "27  United States          USA  GDP (current US$)  2015  1.821930e+13  2015   \n",
      "28          China          CHN  GDP (current US$)  2016  1.113790e+13  2016   \n",
      "29        Germany          DEU  GDP (current US$)  2016  3.495160e+12  2016   \n",
      "30          Japan          JPN  GDP (current US$)  2016  4.926670e+12  2016   \n",
      "31  United States          USA  GDP (current US$)  2016  1.870720e+13  2016   \n",
      "32          China          CHN  GDP (current US$)  2017  1.214350e+13  2017   \n",
      "33        Germany          DEU  GDP (current US$)  2017  3.693200e+12  2017   \n",
      "34          Japan          JPN  GDP (current US$)  2017  4.859950e+12  2017   \n",
      "35  United States          USA  GDP (current US$)  2017  1.948540e+13  2017   \n",
      "36          China          CHN  GDP (current US$)  2018  1.360820e+13  2017   \n",
      "37        Germany          DEU  GDP (current US$)  2018  3.996760e+12  2017   \n",
      "38          Japan          JPN  GDP (current US$)  2018  4.970920e+12  2017   \n",
      "39  United States          USA  GDP (current US$)  2018  2.049410e+13  2017   \n",
      "\n",
      "    Returns  \n",
      "0     12.78  \n",
      "1     12.78  \n",
      "2     12.78  \n",
      "3     12.78  \n",
      "4      0.00  \n",
      "5      0.00  \n",
      "6      0.00  \n",
      "7      0.00  \n",
      "8     13.41  \n",
      "9     13.41  \n",
      "10    13.41  \n",
      "11    13.41  \n",
      "12    13.41  \n",
      "13    13.41  \n",
      "14    13.41  \n",
      "15    13.41  \n",
      "16    29.60  \n",
      "17    29.60  \n",
      "18    29.60  \n",
      "19    29.60  \n",
      "20    11.39  \n",
      "21    11.39  \n",
      "22    11.39  \n",
      "23    11.39  \n",
      "24    -0.73  \n",
      "25    -0.73  \n",
      "26    -0.73  \n",
      "27    -0.73  \n",
      "28     9.54  \n",
      "29     9.54  \n",
      "30     9.54  \n",
      "31     9.54  \n",
      "32    19.42  \n",
      "33    19.42  \n",
      "34    19.42  \n",
      "35    19.42  \n",
      "36    19.42  \n",
      "37    19.42  \n",
      "38    19.42  \n",
      "39    19.42  \n"
     ]
    }
   ],
   "source": [
    "# Use merge_ordered() to merge gdp and sp500, interpolate missing value\n",
    "gdp_sp500 = pd.merge_ordered(gdp, sp500, left_on=\"Year\", right_on=\"Date\", how=\"left\", fill_method='ffill')\n",
    "\n",
    "\n",
    "# Print gdp_sp500\n",
    "print (gdp_sp500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383a1cc8",
   "metadata": {},
   "source": [
    "<b>Instructions:</b>\n",
    "- Subset the gdp_sp500 table, select the gdp and returns columns, and save as gdp_returns.\n",
    "- Print the correlation matrix of the gdp_returns table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abca0d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              GDP   Returns\n",
      "GDP      1.000000  0.040669\n",
      "Returns  0.040669  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Use merge_ordered() to merge gdp and sp500, interpolate missing value\n",
    "gdp_sp500 = pd.merge_ordered(gdp, sp500, left_on='Year', right_on='Date', \n",
    "                             how='left',  fill_method='ffill')\n",
    "\n",
    "# Subset the gdp and returns columns\n",
    "gdp_returns = gdp_sp500[['GDP','Returns']]\n",
    "\n",
    "# Print gdp_returns correlation\n",
    "print(gdp_returns.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece79d65",
   "metadata": {},
   "source": [
    "### Phillips curve using merge_ordered()\n",
    "There is an economic theory developed by A. W. Phillips which states that inflation and unemployment have an inverse relationship. The theory claims that with economic growth comes inflation, which in turn should lead to more jobs and less unemployment.\n",
    "\n",
    "You will take two tables of data from the U.S. Bureau of Labor Statistics, containing unemployment and inflation data over different periods, and create a Phillips curve. The tables have different frequencies. One table has a data entry every six months, while the other has a data entry every month. You will need to use the entries where you have data within both tables.\n",
    "\n",
    "<b>Instructions:</b>\n",
    "- Use merge_ordered() to merge the inflation and unemployment tables on date with an inner join, and save the results as inflation_unemploy.\n",
    "- Print the inflation_unemploy variable.\n",
    "- Using inflation_unemploy, create a scatter plot with unemployment_rate on the horizontal axis and cpi (inflation) on the vertical axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9b4a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can't find the datasets :< Really wanted to this though\n",
    "\n",
    "# Use merge_ordered() to merge inflation, unemployment with inner join\n",
    "inflation_unemploy = pd.merge_ordered(inflation,unemployment, on=\"date\", how=\"inner\")\n",
    "\n",
    "# Print inflation_unemploy \n",
    "print(inflation_unemploy)\n",
    "\n",
    "# Plot a scatter plot of unemployment_rate vs cpi of inflation_unemploy\n",
    "inflation_unemploy.plot(kind=\"scatter\", x=\"unemployment_rate\", y=\"cpi\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afff2fa4",
   "metadata": {},
   "source": [
    "### merge_ordered() caution, multiple columns\n",
    "When using merge_ordered() to merge on multiple columns, the order is important when you combine it with the forward fill feature. The function sorts the merge on columns in the order provided. In this exercise, we will merge GDP and population data from the World Bank for the Australia and Sweden, reversing the order of the merge on columns. The frequency of the series are different, the GDP values are quarterly, and the population is yearly. Use the forward fill feature to fill in the missing data. Depending on the order provided, the fill forward will use unintended data to fill in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b003a369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Indicator Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>ABW</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>2010</td>\n",
       "      <td>101669.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>2010</td>\n",
       "      <td>29185507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angola</td>\n",
       "      <td>AGO</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>2010</td>\n",
       "      <td>23356246.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>ALB</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>2010</td>\n",
       "      <td>2913021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>AND</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>2010</td>\n",
       "      <td>84449.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country Name Country Code     Indicator Name  Year         Pop\n",
       "0        Aruba          ABW  Population, total  2010    101669.0\n",
       "1  Afghanistan          AFG  Population, total  2010  29185507.0\n",
       "2       Angola          AGO  Population, total  2010  23356246.0\n",
       "3      Albania          ALB  Population, total  2010   2913021.0\n",
       "4      Andorra          AND  Population, total  2010     84449.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop = pd.read_csv(\"datasets/WorldBank_POP.csv\")\n",
    "pop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08586fa7",
   "metadata": {},
   "source": [
    "<b>Instructions:</b>\n",
    "- Use merge_ordered() on gdp and pop, merging on columns date and country with the fill feature, save to ctry_date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eade6783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lacking data in given datasets sadt :<. No date column in pop\n",
    "\n",
    "# Merge gdp and pop on date and country with fill and notice rows 2 and 3\n",
    "ctry_date = pd.merge_ordered(gdp,pop, on=[\"date\",\"country\"], \n",
    "                             fill_method='ffill')\n",
    "\n",
    "# Print ctry_date\n",
    "print(ctry_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ba752",
   "metadata": {},
   "source": [
    "<b>Instructions:</b>\n",
    "- Perform the same merge of gdp and pop, but join on country and date (reverse of step 1) with the fill feature, saving this as date_ctry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40baca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No data column in pop\n",
    "\n",
    "# Merge gdp and pop on country and date with fill\n",
    "date_ctry = pd.merge_ordered(gdp, pop, on=[\"country\",\"date\"], fill_method=\"ffill\")\n",
    "\n",
    "# Print date_ctry\n",
    "print(date_ctry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda4d8e9",
   "metadata": {},
   "source": [
    "### Using merge_asof() to study stocks\n",
    "You have a feed of stock market prices that you record. You attempt to track the price every five minutes. Still, due to some network latency, the prices you record are roughly every 5 minutes. You pull your price logs for three banks, JP Morgan (JPM), Wells Fargo (WFC), and Bank Of America (BAC). You want to know how the price change of the two other banks compare to JP Morgan. Therefore, you will need to merge these three logs into one table. Afterward, you will use the pandas .diff() method to compute the price change over time. Finally, plot the price changes so you can review your analysis.\n",
    "\n",
    "<b>Instructions:</b>\n",
    "- Use merge_asof() to merge jpm (left table) and wells together on the date_time column, where the rows with the nearest times are matched, and with suffixes=('', '_wells'). Save to jpm_wells.\n",
    "- Use merge_asof() to merge jpm_wells (left table) and bac together on the date_time column, where the rows with the closest times are matched, and with suffixes=('_jpm', '_bac'). Save to jpm_wells_bac.\n",
    "- Using price_diffs, create a line plot of the close price of JPM, WFC, and BAC only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8440df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use merge_asof() to merge jpm and wells\n",
    "jpm_wells = pd.merge_asof(jpm,wells, on=\"date_time\", suffixes=('', '_wells'), direction='nearest')\n",
    "\n",
    "\n",
    "# Use merge_asof() to merge jpm_wells and bac\n",
    "jpm_wells_bac = pd.merge_asof(jpm_wells, bac, on=\"date_time\",suffixes=('_jpm', '_bac'), direction='nearest')\n",
    "\n",
    "\n",
    "# Compute price diff\n",
    "price_diffs = jpm_wells_bac.diff()\n",
    "\n",
    "# Plot the price diff of the close of jpm, wells and bac only\n",
    "price_diffs.plot(y=['close_jpm','close_wells','close_bac'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
